{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook aims to bring in various liveability features and aggregate them by suburb to be used to answer the 3 key questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import Dependancies\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "import os\n",
    "from shapely.geometry import Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Functions \n",
    "\n",
    "# Define a list of direction words\n",
    "direction_words = ['north', 'south', 'east', 'west']\n",
    "\n",
    "# Function to clean suburb names by removing direction words and \n",
    "# converting to lowercase \n",
    "def clean_suburb_name(suburb):\n",
    "    suburb = suburb.lower()  # Convert to lowercase\n",
    "    for word in direction_words:\n",
    "        suburb = suburb.replace(word, '').strip()\n",
    "    return suburb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\Sampling\\\\real-estate-industry-project-open-source-industry-project-40\\\\notebooks\\\\preprocessing'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load Suburb data\n",
    "landing_directory = '../../data/landing'\n",
    "vic_suburbs = gpd.read_file(f\"{landing_directory}/GDA2020/vic_localities.shp\")\n",
    "\n",
    "#Rename and clean suburb names\n",
    "vic_suburbs.rename(columns={'LOC_NAME': 'suburb_name'}, inplace=True)\n",
    "vic_suburbs['suburb_name_cleaned'] = \\\n",
    "    vic_suburbs['suburb_name'].apply(clean_suburb_name)\n",
    "vic_suburbs.head()\n",
    "\n",
    "# Check for duplicates in the 'suburb' column of aggregate_df\n",
    "duplicates_in_vic_suburbs=\\\n",
    "    vic_suburbs[vic_suburbs.duplicated(subset='suburb_name_cleaned', \n",
    "                                       keep=False)]\n",
    "\n",
    "# Drop duplicates\n",
    "vic_suburbs = vic_suburbs.drop_duplicates(subset='suburb_name_cleaned', \n",
    "                                          keep='first')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tfd\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3373: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\DELL 7590\\AppData\\Local\\Temp\\ipykernel_18444\\4071382905.py:10: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:7844\n",
      "Right CRS: None\n",
      "\n",
      "  joined_data = gpd.sjoin(vic_suburbs, schools, op='contains')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          suburb  num_schools\n",
      "0       abbeyard          0.0\n",
      "1     abbotsford          2.0\n",
      "2     aberfeldie          4.0\n",
      "3      aberfeldy          0.0\n",
      "4        acheron          0.0\n",
      "...          ...          ...\n",
      "2632     yundool          0.0\n",
      "2633      yuroke          0.0\n",
      "2634     yuulong          0.0\n",
      "2635     zeerust          1.0\n",
      "2636   zumsteins          0.0\n",
      "\n",
      "[2637 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "# Find number of schools in each suburb\n",
    "\n",
    "# Load Schools data\n",
    "schools = gpd.read_file(\"../../data/landing/schools\")\n",
    "schools.head()\n",
    "\n",
    "# Map geometry to determine which suburb each school is in \n",
    "schools['geometry'] = \\\n",
    "    schools.apply(lambda row: Point(row['X'], row['Y']), axis=1)\n",
    "joined_data = gpd.sjoin(vic_suburbs, schools, op='contains')\n",
    "\n",
    "# Group by suburb and count how many schools are in each \n",
    "school_counts = \\\n",
    "    joined_data.groupby('suburb_name_cleaned')['School_Name']\\\n",
    "        .count().reset_index()\n",
    "school_counts.rename(columns={'School_Name': 'School_Count'}, inplace=True)\n",
    "\n",
    "# Create the 'aggregate_df' by merging 'vic_suburbs' \n",
    "# and 'school_counts' on 'suburb_name_cleaned' with a left join\n",
    "aggregate_df = \\\n",
    "    vic_suburbs[['suburb_name_cleaned']].merge(school_counts, \n",
    "                                               left_on='suburb_name_cleaned', \n",
    "                                               right_on='suburb_name_cleaned',\n",
    "                                                 how='left')\n",
    "\n",
    "# Rename columns as per your requirement\n",
    "aggregate_df.rename(columns=\n",
    "                    {'suburb_name_cleaned': 'suburb', \n",
    "                     'School_Count': 'num_schools'}, inplace=True)\n",
    "\n",
    "# Fill NaN values in 'num_schools' with 0\n",
    "aggregate_df['num_schools'].fillna(0, inplace=True)\n",
    "\n",
    "# Print or use 'aggregate_df' as needed\n",
    "print(aggregate_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         suburb_name  Hospital_Count\n",
      "0        Mount Eliza               1\n",
      "1  Templestowe Lower               1\n",
      "2            Wodonga               1\n",
      "3          alexandra               1\n",
      "4             altona               1\n",
      "          suburb  num_schools  Hospital_Count\n",
      "0       abbeyard          0.0             0.0\n",
      "1     abbotsford          2.0             0.0\n",
      "2     aberfeldie          4.0             0.0\n",
      "3      aberfeldy          0.0             0.0\n",
      "4        acheron          0.0             0.0\n",
      "...          ...          ...             ...\n",
      "2632     yundool          0.0             0.0\n",
      "2633      yuroke          0.0             0.0\n",
      "2634     yuulong          0.0             0.0\n",
      "2635     zeerust          1.0             0.0\n",
      "2636   zumsteins          0.0             0.0\n",
      "\n",
      "[2637 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Load Healthcare data\n",
    "healthcare = gpd.read_file(f\"{landing_directory}/healthcare_data.csv\")\n",
    "healthcare.head()\n",
    "\n",
    "# Clean suburb names in healthcare data\n",
    "healthcare['suburb_cleaned'] = healthcare['Suburb'].apply(clean_suburb_name)\n",
    "\n",
    "# manually map the 4 hospitals with discrepancies\n",
    "# Define the mapping dictionary for manual corrections\n",
    "corrections = {\n",
    "    'albury': 'Wodonga',\n",
    "    'koo wee rup': 'Koo Wee Rup',\n",
    "    'lower templestowe': 'Templestowe Lower',\n",
    "    'mt eliza': 'Mount Eliza'\n",
    "}\n",
    "\n",
    "# Apply the corrections and create final 'suburb_name' column to use for mapping \n",
    "healthcare['suburb_name'] = healthcare['suburb_cleaned'].replace(corrections)\n",
    "\n",
    "# Group by suburb and count how many hospitals are in each\n",
    "hospital_counts = \\\n",
    "    healthcare.groupby('suburb_name')['Formal Name'].count().reset_index()\n",
    "hospital_counts.rename(columns={'Formal Name': 'Hospital_Count'}, inplace=True)\n",
    "print(hospital_counts.head())\n",
    "\n",
    "# Create the 'final_df' by merging 'aggregate_df' and 'hospital_counts' \n",
    "# on the 'suburb' column with a left join\n",
    "aggregate_df = \\\n",
    "    aggregate_df.merge(hospital_counts, \n",
    "                       left_on='suburb', right_on='suburb_name', how='left')\n",
    "\n",
    "# Drop the 'suburb_name' column from 'hospital_counts' \n",
    "# (if not needed in the final result)\n",
    "hospital_counts.drop('suburb_name', axis=1, inplace=True)\n",
    "\n",
    "# Fill NaN values in 'Hospital_Count' with 0\n",
    "aggregate_df['Hospital_Count'].fillna(0, inplace=True)\n",
    "aggregate_df.drop(columns=['suburb_name'], inplace=True)\n",
    "\n",
    "# Print or use 'final_df' as needed\n",
    "print(aggregate_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tfd\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3373: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\DELL 7590\\AppData\\Local\\Temp\\ipykernel_18444\\3065322085.py:8: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: EPSG:4326\n",
      "Right CRS: EPSG:7844\n",
      "\n",
      "  open_space_with_suburbs = gpd.sjoin(sf, vic_suburbs, how='left', op='within')\n"
     ]
    }
   ],
   "source": [
    "# Bring in Open Space Data\n",
    "\n",
    "sf = \\\n",
    "    gpd.read_file(f\"{landing_directory}/openspace_locations/\\\n",
    "VPA_Draft_Open_Space_Data.shp\")\n",
    "\n",
    "# Spatial join open spaces with suburbs\n",
    "open_space_with_suburbs = gpd.sjoin(sf, vic_suburbs, how='left', op='within')\n",
    "\n",
    "# Extract relevant columns (e.g., 'OpenSpaceName' and 'Suburb') from the result\n",
    "open_space_with_suburbs = open_space_with_suburbs[['FID', \n",
    "                                                   'suburb_name_cleaned']]\n",
    "suburb_open_space_counts = open_space_with_suburbs\\\n",
    "    .groupby('suburb_name_cleaned').size().reset_index(name='OpenSpaceCount')\n",
    "\n",
    "# Merge suburb_open_space_counts with aggregate_df\n",
    "aggregate_df = aggregate_df.merge(suburb_open_space_counts, left_on='suburb', \n",
    "                                  right_on='suburb_name_cleaned', how='left')\n",
    "\n",
    "# Fill NaN values in 'OpenSpaceCount' with 0\n",
    "aggregate_df['OpenSpaceCount'].fillna(0, inplace=True)\n",
    "aggregate_df.drop(columns=['suburb_name_cleaned'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\tfd\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3373: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\DELL 7590\\AppData\\Local\\Temp\\ipykernel_18444\\274688577.py:23: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:7844\n",
      "\n",
      "  gpd.sjoin(metro_buses_stops_gdf, vic_suburbs, how='left', op='within')\n",
      "d:\\tfd\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3373: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\DELL 7590\\AppData\\Local\\Temp\\ipykernel_18444\\274688577.py:25: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:7844\n",
      "\n",
      "  gpd.sjoin(metro_trains_stops_gdf, vic_suburbs, how='left', op='within')\n",
      "d:\\tfd\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3373: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\DELL 7590\\AppData\\Local\\Temp\\ipykernel_18444\\274688577.py:27: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:7844\n",
      "\n",
      "  gpd.sjoin(metro_trams_stops_gdf, vic_suburbs, how='left', op='within')\n",
      "d:\\tfd\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3373: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\DELL 7590\\AppData\\Local\\Temp\\ipykernel_18444\\274688577.py:29: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:7844\n",
      "\n",
      "  gpd.sjoin(reg_buses_stops_gdf, vic_suburbs, how='left', op='within')\n",
      "d:\\tfd\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3373: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\DELL 7590\\AppData\\Local\\Temp\\ipykernel_18444\\274688577.py:31: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:7844\n",
      "\n",
      "  gpd.sjoin(reg_coaches_stops_gdf, vic_suburbs, how='left', op='within')\n",
      "d:\\tfd\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3373: FutureWarning: The `op` parameter is deprecated and will be removed in a future release. Please use the `predicate` parameter instead.\n",
      "  if await self.run_code(code, result, async_=asy):\n",
      "C:\\Users\\DELL 7590\\AppData\\Local\\Temp\\ipykernel_18444\\274688577.py:33: UserWarning: CRS mismatch between the CRS of left geometries and the CRS of right geometries.\n",
      "Use `to_crs()` to reproject one of the input geometries to match the CRS of the other.\n",
      "\n",
      "Left CRS: None\n",
      "Right CRS: EPSG:7844\n",
      "\n",
      "  gpd.sjoin(reg_trains_stops_gdf, vic_suburbs, how='left', op='within')\n"
     ]
    }
   ],
   "source": [
    "# Bring in PTV Data\n",
    "LANDING_DATA_DIR_PTV = \"../../data/landing/ptv\"\n",
    "RAW_DATA_DIR_PTV = \"../../data/raw/ptv\"\n",
    "\n",
    "# Load Shapefiles\n",
    "\n",
    "metro_buses_stops_gdf = \\\n",
    "    gpd.read_file(f\"{RAW_DATA_DIR_PTV}/metro_buses_stops.shp\")\n",
    "metro_trains_stops_gdf = \\\n",
    "    gpd.read_file(f\"{RAW_DATA_DIR_PTV}/metro_trains_stops.shp\")\n",
    "metro_trams_stops_gdf = \\\n",
    "    gpd.read_file(f\"{RAW_DATA_DIR_PTV}/metro_trams_stops.shp\")\n",
    "reg_buses_stops_gdf = \\\n",
    "    gpd.read_file(f\"{RAW_DATA_DIR_PTV}/reg_buses_stops.shp\")\n",
    "reg_coaches_stops_gdf = \\\n",
    "    gpd.read_file(f\"{RAW_DATA_DIR_PTV}/reg_coaches_stops.shp\")\n",
    "reg_trains_stops_gdf = \\\n",
    "    gpd.read_file(f\"{RAW_DATA_DIR_PTV}/reg_trains_stops.shp\")\n",
    "\n",
    "# Count different types of stops within each suburb\n",
    "\n",
    "metro_buses_stops_with_suburbs = \\\n",
    "    gpd.sjoin(metro_buses_stops_gdf, vic_suburbs, how='left', op='within')\n",
    "metro_trains_stops_with_suburbs = \\\n",
    "    gpd.sjoin(metro_trains_stops_gdf, vic_suburbs, how='left', op='within')\n",
    "metro_trams_stops_with_suburbs = \\\n",
    "    gpd.sjoin(metro_trams_stops_gdf, vic_suburbs, how='left', op='within')\n",
    "reg_buses_stops_with_suburbs = \\\n",
    "    gpd.sjoin(reg_buses_stops_gdf, vic_suburbs, how='left', op='within')\n",
    "reg_coaches_stops_with_suburbs = \\\n",
    "    gpd.sjoin(reg_coaches_stops_gdf, vic_suburbs, how='left', op='within')\n",
    "reg_trains_stops_with_suburbs = \\\n",
    "    gpd.sjoin(reg_trains_stops_gdf, vic_suburbs, how='left', op='within')\n",
    "\n",
    "# Group by suburb and count the number of stops for each type of public trans\n",
    "metro_buses_counts = \\\n",
    "    metro_buses_stops_with_suburbs\\\n",
    "        .groupby('suburb_name_cleaned').size().\\\n",
    "            reset_index(name='MetroBusesCount')\n",
    "metro_trains_counts = \\\n",
    "    metro_trains_stops_with_suburbs.groupby('suburb_name_cleaned')\\\n",
    "        .size().reset_index(name='MetroTrainsCount')\n",
    "metro_trams_counts =\\\n",
    "      metro_trams_stops_with_suburbs.groupby('suburb_name_cleaned')\\\n",
    "        .size().reset_index(name='MetroTramsCount')\n",
    "reg_buses_counts = \\\n",
    "    reg_buses_stops_with_suburbs.groupby('suburb_name_cleaned')\\\n",
    "        .size().reset_index(name='RegBusesCount')\n",
    "reg_coaches_counts = \\\n",
    "    reg_coaches_stops_with_suburbs.groupby('suburb_name_cleaned')\\\n",
    "        .size().reset_index(name='RegCoachesCount')\n",
    "reg_trains_counts = \\\n",
    "    reg_trains_stops_with_suburbs.groupby('suburb_name_cleaned')\\\n",
    "        .size().reset_index(name='RegTrainsCount')\n",
    "\n",
    "\n",
    "# Merge the counts for each type of stop into a single DataFrame\n",
    "transport_stops_counts = metro_buses_counts.merge(metro_trains_counts, \n",
    "                                                  on='suburb_name_cleaned', \n",
    "                                                  how='left')\n",
    "transport_stops_counts = transport_stops_counts.merge(metro_trams_counts, \n",
    "                                                      on='suburb_name_cleaned',\n",
    "                                                        how='left')\n",
    "transport_stops_counts = transport_stops_counts.merge(reg_buses_counts, \n",
    "                                                      on='suburb_name_cleaned',\n",
    "                                                        how='left')\n",
    "transport_stops_counts = transport_stops_counts.merge(reg_coaches_counts, \n",
    "                                                      on='suburb_name_cleaned', \n",
    "                                                      how='left')\n",
    "transport_stops_counts = transport_stops_counts.merge(reg_trains_counts, \n",
    "                                                      on='suburb_name_cleaned',\n",
    "                                                        how='left')\n",
    "\n",
    "# Sum the counts for each type of stop to get the total public transport stops\n",
    "transport_stops_counts['TotalPublicTransportStops'] = \\\n",
    "    transport_stops_counts[['MetroBusesCount', 'MetroTrainsCount', \n",
    "                            'MetroTramsCount', 'RegBusesCount', \n",
    "                            'RegCoachesCount', 'RegTrainsCount']].sum(axis=1)\n",
    "\n",
    "# Define the columns to include in the TotalBusStops and TotalTrainStops\n",
    "bus_columns = ['MetroBusesCount', 'RegBusesCount', 'RegCoachesCount']\n",
    "train_columns = ['MetroTrainsCount', 'RegTrainsCount']\n",
    "\n",
    "# Create the TotalBusStops and TotalTrainStops columns and drop sub categories\n",
    "transport_stops_counts['TotalBusStops'] = \\\n",
    "    transport_stops_counts[bus_columns].sum(axis=1)\n",
    "transport_stops_counts['TotalTrainStops'] = \\\n",
    "    transport_stops_counts[train_columns].sum(axis=1)\n",
    "transport_stops_counts = \\\n",
    "    transport_stops_counts.drop(columns=bus_columns)\n",
    "transport_stops_counts = \\\n",
    "    transport_stops_counts.drop(columns=train_columns)\n",
    "\n",
    "# Merge transport_stops_counts with aggregate_df\n",
    "aggregate_df = \\\n",
    "    aggregate_df.merge(transport_stops_counts, \n",
    "                       left_on='suburb', right_on='suburb_name_cleaned', \n",
    "                       how='left')\n",
    "\n",
    "# Fill NaN values in count columns with 0\n",
    "columns_to_fill = ['TotalBusStops', 'TotalTrainStops', \n",
    "                   'TotalPublicTransportStops']\n",
    "aggregate_df[columns_to_fill] = aggregate_df[columns_to_fill]\\\n",
    "    .fillna(0).astype(int)\n",
    "aggregate_df.drop(columns=['suburb_name_cleaned'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load crime data\n",
    "\n",
    "crime_path = '../../data/landing/crime_data.xlsx'\n",
    "crime_df = pd.read_excel(crime_path,sheet_name='Table 03')\n",
    "crime_df['crime_suburb'] = crime_df['Suburb/Town Name']\\\n",
    "    .apply(clean_suburb_name)\n",
    "\n",
    "# Group crime by suburb\n",
    "crime_counts = crime_df.groupby('crime_suburb').size()\\\n",
    "    .reset_index(name='crime_count')\n",
    "\n",
    "# Join to aggregate df\n",
    "aggregate_df = aggregate_df.merge( crime_counts, left_on='suburb',\n",
    "                                   right_on='crime_suburb', how='left')\n",
    "aggregate_df = aggregate_df.drop(columns=['crime_suburb'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>suburb</th>\n",
       "      <th>num_schools</th>\n",
       "      <th>Hospital_Count</th>\n",
       "      <th>OpenSpaceCount</th>\n",
       "      <th>MetroTramsCount</th>\n",
       "      <th>TotalPublicTransportStops</th>\n",
       "      <th>TotalBusStops</th>\n",
       "      <th>TotalTrainStops</th>\n",
       "      <th>crime_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>754</th>\n",
       "      <td>melbourne</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>32</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4517.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        suburb  num_schools  Hospital_Count  OpenSpaceCount  MetroTramsCount  \\\n",
       "754  melbourne          1.0            14.0            53.0             22.0   \n",
       "\n",
       "     TotalPublicTransportStops  TotalBusStops  TotalTrainStops  crime_count  \n",
       "754                         32              9                1       4517.0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregate_df[aggregate_df['suburb'] == 'melbourne']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns for consistency\n",
    "# Create a mapping of old column names to new column names\n",
    "column_mapping = {\n",
    "    'num_schools': 'schools_count',\n",
    "    'Hospital_Count': 'hospital_count',\n",
    "    'OpenSpaceCount': 'open_space_count',\n",
    "    'MetroTramsCount': 'trams_count',\n",
    "    'TotalPublicTransportStops': 'public_transport_stops_count',\n",
    "    'TotalBusStops': 'bus_stops_count',\n",
    "    'TotalTrainStops': 'train_stops_count',\n",
    "    'crime_count': 'crime_count'\n",
    "}\n",
    "\n",
    "# Use the rename() method to rename the columns\n",
    "aggregate_df = aggregate_df.rename(columns=column_mapping)\n",
    "\n",
    "# Save to curated data folder \n",
    "\n",
    "CURATED_DATA_DIR = \"../../data/curated\"\n",
    "filename = \"liveability_features.csv\"\n",
    "aggregate_df.to_csv(f\"{CURATED_DATA_DIR}/{filename}\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
